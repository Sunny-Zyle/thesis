\chapter{Türerkennung}

Die Türerkennung erfolgt in mehreren Schritten. Zuerst wird im Bild nach Liniensegmenten gesucht. Die gefundenen Segmente müssen hinsichtlich Länge und Ausrichtung optimiert werden. Anschliessend muss nach möglichen Vier-Kanten-Paaren gesucht werden, welche möglicherweise eine Tür bilden. Die gefundenen Kandidaten werden dann noch evaluiert, um den besten Treffer zu bestimmen.

\section{Kantendetektion}

Es existieren verschiedene Algorithmen um Kanten in Bildern zu suchen. In dieser Arbeit wurden speziell die \textit{Probabilistic Hough Transform} und die \textit{Line Segment detection using Weighted Mean-Shift} oder kurz LSWMS untersucht. Beide sind darauf spezialisiert Geraden zu finden, wobei es merkliche Unterschiede zwischen den zwei Methoden gibt.

\subsection{Probabilistic Hough Transform}

In der Literatur wird der Term Probabalistic Hough Transform (PHT) mit verschiedenen Ideen bezüglich der Optimierung der Standard Hough Transform (SHT) assoziiert. Wir beziehen uns auf die Methode von Kiryati \cite{kiryati} welche Stichproben verwendet um die Effizienz der SHT zu verbessern.
\paragraph{}
Die Standard Hough Transform wird dazu verwendet um die Parameter von Features, wie in unserem Fall Linien, zu ermitteln. Als Ausgangspunkt wird ein Binärbild verwendet, in welchem jedes aktive Pixel (weiss) Teil einer Kante oder Linie aus dem Originalbild ist. Die SHT bildet jedes dieser Pixel auf verschiedene Punkte im Hough Raum ab, in Form eines Sinusoiden. Dieser stellt alle Linien dar welche durch diesen Pixel verlaufen könnten. Diese Abbildungsphase wird auch Voting Phase genannt. Sind mehrere aktive Pixel colinear, so werden sich ihre Sinusoiden kreuzen. Sucht man nun die Punkte im Hough Raum wo sich viele Sinusoiden kreuzen, kann man daraus die Parameter der Linien im Originalbild bestimmen.
\paragraph{}
Im Unterschied zur Standard Hough Transform verwendet die Probabalistic Hough Transform nur einen Teil, eine Stichprobe, der aktiven Pixel im Binärbild. Die PHT geht davon aus, dass ein Anteil $\alpha$ (0\% < $\alpha$ < 100\%) ausreicht um die Parameter der Linien im Bild zu ermitteln. Kiryati kam zum Ergebnis, dass ab einem bestimmten Threshold $\alpha_t$ vermehrt False-Positives bei der Detektion auftreten. Wählt man mit Hilfe einer Probability Density Function ein Subset $\alpha$ $\approx$ $\alpha_t$ so kann man den Rechenaufwand erheblich reduzieren ohne signifikante Abstriche bei der Qualität der Ergebnisse machen zu müssen. Der Bereich von $\alpha_t$ liegt bei 5\%-15\%, je nach Anwendungsfall.

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.25]{images/hough-transform} 
\caption{Verarbeitungsschritte der Standard Hough Transform. Ausgangsbild, Binärbild, Hough Raum und die gefundenen Linien. Quelle \cite{kiryati}}
\label{fig:hough-transform}
\end{figure}

\pagebreak

\subsection{Line Segment detection using Weighted Mean-Shift}

\begin{figure}[!ht]
\centering
\includegraphics[width=\textwidth]{images/lswms} 
\caption{Ablaufschema des LSWMS Algorithmus. Im ersten Teil wird die Wahrscheinlichkeitsverteilung $\hat{p}(x,y)$ anhand der Parameter $\mu_1$ und $\mu_2$ ermittelt. Im zweiten Teil wird das erste Sample generiert und der Slice-Sampling-Prozess wird gestartet, um kontinuierlich Stichproben $z_k$ zu erhalten. Im dritten und letzten Teil werden die Samples verfeinert und als Ausgangspunkte für das iterative Line-Growing verwendet, welches die gesuchten Liniensegmente liefert. Quelle \cite{nieto}}
\label{fig:lswms}
\end{figure}
\noindent
Abb. \ref{fig:lswms} veranschaulicht den Ablauf des "Line Segment detection using Weighted Mean-Shift" (LSWMS) Algorithmus. Im ersten Teil wird die Wahrscheinlichkeitsverteilung für jedes Pixel von Bild $I$ berechnet, so dass $\hat{p}(x, y)$ angibt, wie wahrscheinlich es ist, dass das Pixel $(x, y$) Teil eines Liniensegmentes ist. Diese Wahrscheinlichkeitsverteilung, parametrisiert durch $\mu_1$ und $\mu_2$, wird anhand der Tensor Matrix und den dazugehörigen Eigenvalues errechnet. Gute Kandidatenpixel müssen zwei Bedingungen erfüllen. Zum einen muss der Betrag des Gradienten auf eine gewisse Signifikanz des Pixels hindeuten und zum anderen muss eine dominante Gradienten-Richtung in der Nachbarschaft des Pixels vorhanden sein.
\paragraph{}
Der zweite Teil \textit{sequential sampling} selektiert, basierend auf $\hat{p}(x,y)$, kontinuierlich Pixel ($z_k$) welche eine hohe Wahrscheinlichkeit besitzen zu einem Liniensegment zu gehören. Gleichzeitig wird sichergestellt, dass kein Pixel eines Segmentes mehrmals gesampelt wird. Dies ist ein wichtiger unterschied zu PHT, da es die Effizienz von LSWMS im Vergleich zu PHT erhöht. Der Slice Sampler basiert auf dem Markov-Chain-Monte-Carlo-Verfahren\footnote{\protect\url{http://de.wikipedia.org/wiki/MCMC-Verfahren}}, welches es erlaubt kontinuierlich Stichproben aus einer bestimten Wahrscheinlichkeitsverteilung $p$ zu ziehen, welche in unserem Fall die Qualität des Kandidatenpixel angibt.
\paragraph{}
Die Wahrscheinlichkeitsverteilung wird beim LSWMS Algorithmus anhand der Eigenvalues $(\lambda_1, \lambda_2)$ eines jeden Pixel berechnet. Wobei $f$ die Eigenvalues $(\lambda_1, \lambda_2)$ zu einem beliebigen Pixel $(x, y)$ zurückgibt.

\begin{equation}
\begin{split}
p = g \circ f:  &I \to (\lambda_1, \lambda_2) \to \mathbb{R} \\
                &(x, y) \mapsto \hat{p}(x, y) = g(f(x, y))
\end{split}
\end{equation}
\noindent
Die Funktion erfüllt zwei wichtige Kriterien. Zum einen gibt sie nur hohe Werte zurück für Eigenvalues-Paare bei dem ein Wert deutlich grösser ist als der andere. Zum anderen fällt der Wert rapide ab, wenn beide Werte hoch oder tief sind. $g$ gibt die Wahrscheinlichkeit an, dass ein Eigenvalue-Paar zu einem Liniensegment gehört.

\begin{equation}
g(\lambda_1, \lambda_2) = (1 - exp(-\lambda_1/\mu_1)) exp(-\lambda_2/\mu_2)
\end{equation}
\noindent
$\mu_1$ und $\mu_2$ sind die Durchschnittswerte aller Eigenvalues über das ganze Bild. Diese wurden im ersten Teil ermittelt. Stellt man die Verteilung visuell dar, so ergibt sich das Bild in Abb. \ref{fig:lswms-eigenvalues}.

\begin{figure}[!ht]
\centering
\includegraphics[width=\textwidth]{images/lswms-eigenvalues} 
\caption{Eigenvalues welche die Gradientenstruktur abbilden. Die schwarzen Punkte sind die Werte der Nachbarpixel eines Pixels $(I_x, I_y)$. a) Verteilung eines Liniensegmentes. b) Verteilung einer Ecke oder einer heterogenen Gradienten. Quelle \cite{nieto}}
\label{fig:lswms-eigenvalues}
\end{figure}
\noindent
\paragraph{}
Basierend auf diesen Grundlagen werden die Liniensegmente wie folgt ermittelt. Initial wird iterativ ein erster Kandidatenpixel gesucht, welcher die Bedingung $\hat{p}(x, y) > \mu$ erfüllt. $\mu$ ist der Mittelwert von $\hat{p}(x, y)$ über das ganze Bild. Dies stellt sicher, das für den Schritt der Segmentgenerierung eine optimale Ausgangslage geschaffen wird. So gibt es so wenig Fehlversuche wie möglich. Nachfolgend such der Sampler Pixel mit einem ähnlichen Wert für $\hat{p}(x, y)$ wie der Initialpixel. Jedes mal wenn ein Liniensegment generiert wird, werden sämtliche Pixel des Segmentes aus dem Pool der Pixel aus dem der Sampler wählt entfernt. Auch, werden die Nachbarpixel innerhalb einer definierten Fensters von $r x r$ entfernt, wobei r die räumliche Weite des Mean Shift ist. Aufgrund dieser Tatsache kann der Fall eintreten, dass der Slice Sampler feststellt, dass alle Pixel in der Nachbarschaft des initialen Pixels bereits verarbeitet wurden. In diesem Fall wird ein neuer Initialpixel gesucht, welcher die gegebenen Kriterien erfüllt. Der Sampler sucht so lange nach neuen Kandidaten bis keine geeigneten mehr gefunden werden oder bis eine gegebene Obergrenze bei der Anzahl zu suchender Liniensegmente erreicht wurde.
\paragraph{}
Die geeigneten Bildpunkte welche vom Slice Sampler ermittelt werden, werden kontinuierlich dem Line Segment Generator übergeben. Erhält dieser ein Sample $z_k$ und die dazugehörige Orientierung der Normalen $\theta_k$, so steuert er die Richtung des Generierungsprozesses anhand des Vektors $\textbf{x}_{k} = (x_k, y_k, \theta_k)$. Obwohl der Sampler bereits sehr gute Kandidaten liefert, besteht immer noch die Möglichkeit, dass in der Nachbarschaft von $\textbf{x}_k$ ein Bildpunkt mit einem höheren Wert für $\hat{p}(x, y)$ vorhanden ist. Aus diesem Grund wird mittels Weighted Mean Shift (wMS) nach einem Optimum $\hat{\textbf{x}}_k$ gesucht. Mean Shift (MS) ist ein iterativer, parameterfreier Algorithmus, welcher dazu eingesetzt werden kann lokale Maxima einer unbekannten Dichtefunktion zu ermitteln, wenn eine Menge von Samples vorhanden ist. Bei jeder Iteration startet MS bei einer initialen Stichprobe und bewegt sich in Richtung der dichtesten Region innerhalb des Suchraumes. LSWMS gewichtet die Stichproben zusätzlich noch anhand der zuvor berechneten Wahrscheinlichkeiten $\hat{p}$.
\paragraph{}
Anhand des verfeinerten Punktes $\hat{\textbf{x}}_k = (\hat{x}_k, \hat{y}_k, \hat{\theta}_k)$ wird dann die Generierung des Segmentes vorgenommen, basierend auf dem Bresenham Algorithmus \cite{bresenham}. Das obere Segment in der Abb. \ref{fig:lswms-line-growing}a veranschaulicht diesen Vorgang.

\begin{figure}[!ht]
\centering
\includegraphics[width=\textwidth]{images/lswms-line-growing} 
\caption{Oriented Line Growing. a) Oberes Segment mit einer genauen Wachstumsrichtung. Unteres segment mit einem Wachstumsprozess welcher eine Verfeinerung der Richtung benötigt. b) In beiden Fällen wurde ein korrektes Segment ermittelt, welches sich innerhalb des Gradienten der Kante befindet. Quelle \cite{nieto}}
\label{fig:lswms-line-growing}
\end{figure}

\subsection{Evaluation}

Die Entscheidung fiel auf den LSWMS Algorithmus, aus mehreren Gründen. LSWMS wurde von Anfang an für die unbeaufsichtigte Kantendetektion innerhalb von Echtzeitanwendungen konzipiert. Da die Umgebungen in denen die Türdetektion stattfindet stark variieren können, ist es nicht möglich im vorhinein fixe Parameter für die Hough-Transformation zu definieren, welche überall gleich gut funktionieren. LSWMS bietet im Schnitt unter sich verändernden Verhältnissen die bessere Leistung. Der Algorithmus erforder zwar auch einen Parameter r, welcher oben erklärt wurde, jedoch kann dieser auf dem Standardwert 3 belassen werden. Mit diesem gibt LSWMS akzeptable Resultate zurück.
\paragraph{}
Ein weiterer Faktor ist die Qualutät der zurückgegebenen Resultate. Die Anzahl fehlerhaft erkannten Kanten ist bei Hough erheblich höher als bei LSWMS und wirkt sich damit auch auf die Performance der weiteren Verarbeitungsschritte negativ aus. Die Möglichkeit bei LSWMS eine Obergrenze bezüglich der Anzahl erwarteter Treffer angeben zu können war ebenfalls ausschlaggebend. Bei "ruhigen" Bildern mit wenig potentiellen Kanten wirkt sich dies wenig aus. Bilder welche z.B. Türe mit Holzmuster enthalten führen bei Hough zu einer Fehlerquote von teilweise über 50\%.
\paragraph{}
Der letzte Faktor welcher zur Entscheidung geführt hat LSWMS vorzuziehen war die Gesamtperformance. Hough benötigt als Input ein Kantenbild, welches zuvor mit einem separaten Algorithmus aufgearbeitet werden muss, z.B. Canny\footnote{\protect\url{http://de.wikipedia.org/wiki/Canny-Algorithmus}}. Dieser Schritt führt zusätzliche Parameter ein, welche situationsbedingt optimiert werden müssen und erhöht die Verarbeitungszeit der Hough-Transformation. Da Canny empfindlich gegenüber Rauschen im Bildmaterial ist, muss ein weiterer Verarbeitungsschritt vorangestellt werden. Bevor Canny angewendet wird, werden mittels einem Gausschen Filter Störfaktoren reduziert. Um ein optimales Ergebnis zu erhalten müssen vertikale und horizontale Kanten separat gesucht werden. Dies hat zu folge das die Hough-Transformation zweimal dürchgeführt werden muss (Canny muss nur einmal angewendet werden, beide Male kann das selbe Kantenbild verwendet werden).
\paragraph{}
Für den Vergleich der Hough-Transformation und LSWMS wurden folgende Parameter verwendet:
\paragraph{}
Gauss Filter (medianBlur)\footnote{\protect\url{http://docs.opencv.org/modules/imgproc/doc/filtering.html?highlight=medianblur#medianblur}}
\begin{itemize}
	\item kSize: 5
\end{itemize}
Canny Edge Detection\footnote{\protect\url{http://docs.opencv.org/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.html}}
\begin{itemize}
	\item lowThreshold: 20
	\item highThreshold: 80
	\item kernelSize: 3
\end{itemize}
Probabilistic Hough Transform\footnote{\protect\url{http://docs.opencv.org/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.html}}
\begin{itemize}
	\item rho: 1
	\item theta: 1 rad
	\item threshold: 80
	\item minLinLength: 30
	\item maxLineGap: 10
\end{itemize}
LSWMS
\begin{itemize}
	\item numMaxLSegs: 1000
\end{itemize}
\noindent
Die gelben Linien stellen die gefundenen Kanten bzw. Kanstensegmente dar.
\pagebreak

\begin{figure}
\subfloat[Ergebnis Hough-Transformation]{\includegraphics[width=0.47\textwidth]{images/hough-raw-segments}}\qquad
\subfloat[Ergebnis LSWMS]{\includegraphics[width=0.47\textwidth]{images/lswms-raw-segments}}
\caption{Vergleich PHT und LSWMS}
\label{fig:comp-pht-lswms}
\end{figure}
\noindent
Dies ist nur ein Bild von zehn getesteten. Die Bilder welche während der Entwicklung zum Testen verwendet wurden können im Projektverzeichnis unter Data/Images/Doors/Misc gefunden werden. Es ist klar ersichtlich, dass LSWMS das qualitativ bessere Ergebnis liefert. Einziger Nachteil hier ist, dass LSWMS oft nicht durgehende Kanten erkennt sondern kleinere Segmente entlang der Kante zurückgibt. Neben der Qualität der Resultate wurde auch die Performance beider Methoden analysiert. Da einige Testbilder grösser sind als in der finalen Applikation benötigt, wurden alle Bilder auf eine Höhe von 800 Pixel verkleinert. Nachfolgend das Ergebnis (Durchschnitt aus 100 Durchgängen):

\begin{itemize}
	\item Hough: 165ms, 1871 Segmente
	\item LSWMS: 64ms, 868 Segmente
\end{itemize}
\noindent
Auch hier ist LSWMS Hough überlegen. Obwohl LSWMS für Echtzeitanwendungen konzipiert wurde, kann mit den gemessenen 64ms Verarbeitungszeit pro Frame kein flüssiges Videobild bei 28fps wiedergegeben werden.

\section{Fluchtpunktbestimmung}
Um die horizontalen und vertikalen Fluchtpunkte zu bestimmen, wird der von Marco Nietos entwickelte \cite{nieto-msac} auf MSAC (\textbf{M}-Estimator \textbf{Sa}mple and \textbf{C}onsensus) basierte Algorithmus eingesetzt. Die Implementation von Nietos weicht insofern vom standard MSAC ab, als das eine nicht-lineare Bewertungsfunktion eingesetzt wird und, dass zusätzlich ein Tracking der Fluchtpunkte vollzogen wird. Dies ermöglicht es, Vorraussagen zur Position der Fluchtpunkte zu treffen, basierend auf den Resultaten der vorherigen Video-Frames. Dies reduziert die Rechenzeit signifikant und ermöglicht den Einsatz von MSAC in Echtzeitanwendungen.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.5\textwidth]{images/msac} 
\caption{Reduktion der benötigten Iterationsscritte mit Hilfe von Fluchpunkt-Tracking. Quelle: \cite{nieto-msac}}
\label{fig:door-detection}
\end{figure}

\section{Implementation}

\begin{figure}[!ht]
\centering
\includegraphics[width=\textwidth]{images/door-detection} 
\caption{Ablauf der Türerkennung}
\label{fig:door-detection}
\end{figure}
\noindent
Wie bereits zu beginn des Kapitels erwähnt, besteht der Prozess der Türerkennung aus mehreren Teilschritten (Abb. \ref{fig:door-detection}). Als erstes wird der LSWMS Algorithmus angewendet. Dieser Arbeitet auf Graustufenbildern. Somit wird der Input entsprechend konvertiert. Da die Lichtverhältnisse vor allem an den Türkanten oft suboptimal sind, aufgrund eines leichten Schattenwurfes, wird eine Contrast Limited Adaptive Histogram Equialization (CLAHE) angewendet mit einem Clip Limit von 5 und einer Fenstergrösse von 8. Diese Werte wurden experimentell ermittelt. Der Grund, dass CLAHE angewendet wurde und keine normale (Adaptive) Histogram Equalization ist, dass festgestellt wurde, dass die Verstärkung von Rauschen und von feinen Muster (z.B. Holzmaserungen) die Qualität der Resultate von LSWMS verringert. Weiterhin ist es wichtig, dass die Regionen um die Tür herum ausgebessert werden. Dies ist damit gegeben, dass CLAHE den Kontrast immer innerhalb eines bestimmten Fensters ausgleicht. Um sichtbare Kanten der einzelnen Fenster zu vermeiden, wird die Randregion noch interpoliert. Der Unterschied der globalen Histogram Equalization und CLAHE wird in Abb. \ref{fig:clahe} verdeutlicht. Ein Beispiel wie die Ausgabe der LSWMS Erkennung aussieht, ist in Abb. \ref{fig:lswms-output} ersichtlich. Der Algorithmus wurde zusätzlich noch für diese spezielle Anwendung optimiert. Zu kurze Segmente werden bereits bei der Suche verworfen. Weiterhin wurde der Mean Shift teil entfernt. Dieser dient rein der Fehlerkorrektur. LSWMS gibt aber auch ohne diese Berechnung gute Resultate zurück. Der Mean Shift ist der Rechenintensivste Teil des Algorithmus. Durch den Ausbau konnte die Verarbeitungszeit um 70\% reduziert werden. Nur so konnte der oben genannte, deutliche Performancegewinn gegenüber PHT erreicht werden.

\begin{figure}
\subfloat[Ausgangsbild]{\includegraphics[width=0.47\textwidth]{images/clahe-orig}}\qquad
\subfloat[Global Histogram Equalization]{\includegraphics[width=0.47\textwidth]{images/clahe-ghe}}\qquad
\subfloat[Contrast Limited Adaptive Histogram Equialization]{\includegraphics[width=0.47\textwidth]{images/clahe}}\qquad
\caption{Vergleich Global Histogram Equalization und CLAHE}
\label{fig:clahe}
\end{figure}

\begin{figure}
	\subfloat[Segmente wie sie von LSWMS gefunden werden]{\includegraphics[width=0.45\textwidth]{images/seg-raw}\label{fig:lswms-output}}\qquad	
	\subfloat[Segmente kategorisiert in horizontal (Rot) und vertikal (Gelb)]{\includegraphics[width=0.45\textwidth]{images/seg-categorized}\label{fig:segs-categorized}}\qquad	
	\subfloat[Verschmolzene Segmente]{\includegraphics[width=0.45\textwidth]{images/seg-joined}}	\qquad	
	\subfloat[Verlängerte Segmente]{\includegraphics[width=0.45\textwidth]{images/seg-grow}}	
	\caption{Verarbeitungsprozess Türerkennung}
\end{figure}

\begin{figure}
	\ContinuedFloat
	\centering		
	\subfloat[Gefundene Kandidaten]{\includegraphics[width=0.45\textwidth]{images/seg-candidates}\label{fig:seg-candidates}}\qquad
	\subfloat[Erkannte Tür]{\includegraphics[width=0.45\textwidth]{images/seg-detected}}\qquad
	\caption{Verarbeitungsprozess Türerkennung}
	\label{fig:door-detection}
\end{figure}

\subsection{Fluchtpunkt-Bestimmung / Kategorisierung}
Im nächsten Schritt werden die Fluchtpunkte (horizontal und vertikal) bestimmt. Dies geschieht mit Hilfe des MSAC-Algorithmus. Während der Fluchpunktbestimmung werden die Segmente in Cluster zusammengefasst um die Position der Punkte zu ermitteln. Das Clustering ist gleichzeitig auch eine Kategorisierung, da ein Cluster alle horizontalen und der andere alle vertikalen Liniensegmente enthält. Dies spart einen zusätzlichen Verarbeitungsschritt und damit auch Rechenzeit.

\subsection{Segment Joining}
Da die gefundenen Kanten oft nicht aus durchgehenden Segmenten bestehen sondern aus mehreren kleinen (Abb. \ref{fig:segments-pre-join}), müssen in diesem Schritt Liniensegmente die nahe bei einander liegen und eine änhliche Ausrichtung haben verschmolzen werden. Dabei wird wie folgt vorgegangen. Als erstes wird die Distanz der Segmente berechnet. Dabei müssen mehrere Fälle unterschieden werden.

\begin{itemize}
	\item Segmente sind parallel $\Rightarrow$ Die Distanz kann von jedem Punkt aus in der "Überlappungszone" bestimmt werden kann.
	\item Segmente stehen schief zueinander $\Rightarrow$ Die Segmentpunkte mit der geringsten Distanz müssen ermittelt werden.
	\item Segmente haben keine "Überlappungszone" $\Rightarrow$ Distanz von End- zu Startpunkt wird berechnet
	\item Segmente kreuzen sich $\Rightarrow$ Schnittpunkt muss ermittelt werden
\end{itemize}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.5\textwidth]{images/segments-pre-join} 
\caption{Segmente vor der Verschmelzung (gezoomt)}
\label{fig:segments-pre-join}
\end{figure}
\noindent
Eine Distanz von max. 8px hat sich als guter Wert erwiesen. Wurden zwei Segmente gefunden die nahe genug beieinander sind, wird das Segment Joining initialisiert. Hier wird zuerst überprüft, ob es Sinn macht die Segmente zu vereinen. Liegt ein Segment innerhalb des Bereiches des anderen, so macht dies keinen Sinn, da das Segment nicht erweiter wird (Abb. \ref{fig:segment-joining-1}).

\begin{figure}[!ht]
\centering
\includegraphics[width=0.5\textwidth]{images/segment-joining-1} 
\caption{Hier macht es keinen Sinn die zwei Segmente zu verschmelzen}
\label{fig:segment-joining-1}
\end{figure}
\noindent
Ist dies nicht der Fall, so werden die zwei Segmente zum Fluchtpunkt hin ausgerichtet. Dies geschieht, indem die Endpunkte auf die Gerade abgebildet werden, welche den Fluchtpunkt und den Mittelpunkt des Segmentes verbindet. Die Abbildungen bilden dann die neuen Endpunkte (Abb. \ref{fig:segment-joining-3}). Anschliessend werden die Längen addiert und das neue Segment wird zwischen den zwei Ausgangssegmenten platziert (Abb. \ref{fig:segment-joining-2}).

\begin{figure}[!ht]
\centering
\includegraphics[width=0.5\textwidth]{images/segment-joining-3} 
\caption{Ausrichtung des Segmentes hin zum Fluchtpunkt}
\label{fig:segment-joining-3}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.5\textwidth]{images/segment-joining-2} 
\caption{Ausgangssegmente grau und verschmolzenes Segment rot}
\label{fig:segment-joining-2}
\end{figure}

\subsection{Kandidatensuche}
Nun gehr es darum Vierer-Paare von Liniensegmenten zu finden, welche eine Tür darstellen könnten (Abb. \ref{fig:seg-candidates}). Währen der Implementation der Suche hat sich ergeben, dass die Segmente welche die Tür umgeben sich nicht kreuzen. Aus diesem Grund werden die Linien vor der Suche noch um 5\% der Diagonalenlänge verlängert. Mit diesem Wert konnte in allen Tests sichergestellt werden, dass sich die Türsegmente überlappen. 
\paragraph{}
Nun wird nach der Tür gesucht. Hierfür werden als erstes die vertikalen Kanten evaluiert. Diese müssen einen gewissen Türhöhre bilden (25\% der Diagonallänge). Damit gehen wir davon aus, dass die Tür an sich im Bild eine gewisse Grösse hat. Dies lässt sich nicht vermeiden, um nicht fälschlicherweise Fenster als Türen zu erkennen. Anschliessen wird nach passenden horizontalen Segmenten gesucht. Diese müssen die vertikalen Kanten kreuzen.

\subsection{Kandidatenevaluation}
In diesem letzten Schritt werden die gefundenen Kandidaten bewertet. Dabei wird das Seitenverhältnis Höhe zu Breite von diesen ausgewertet. Es wurden verschidene Türtypen aufgenommen und im Internet gesucht um zu erruieren, was in etwa das Standardmass einer Durchschnitttür ist. Es sind zwar DIN-Normen vorhanden, diese weichen aber stark von den meisten Türen ab welche untersucht wurden. Die DIN-Norm für eine einflüglige Türe hat ein Seitenverhältnis von 7.2. Durch Auswertung von 30 Aufnahmen wurde aber ein Verhältnis von 4.91 errechnet. In den Tests hat sich dieses klar als besser herausgestellt in 100\% der Fälle. Da die Proportionen perspektivisch Verzerrt sein können, wird das Seitenverhältnis der Kanten mit der unter Abschnitt \ref{sec:door-ratio-calculation} beschriebenen Methode berechnet.
\paragraph{}
Es wurden auch diverse andere mögliche Evaluationskriterien getestet, jedoch haben sich diese nicht bewährt. Ein Ansatz war, die farbliche Homogenität der Fläche der Kandidaten zu bewerten. Aufgrund von Schattenwurf, Fenstern und Mustern auf vielen Türen hat sich dies nicht bewährt. Ein anderer Ansatz war, den Türgriff zu suchen. Da die Vielfalt hier aber enorm gross ist und der Griff oft zu klein ist auf den Bildern um ihn zu Analysieren, wurde auch dieses Kriterium fallen gelassen. Generell ist es sehr schwierig bei Aussentüren einen gemeinsamen Nenner zu finden. Die Evaluation der Seitenverhältnisse allein liefert aber in vielen Fällen bereits gute Resultate.

\subsection{Performance}
Die Performance wurde anhand von 100 Durchläufen auf 10 verschiedene Bilder gemessen.

\begin{itemize}
	\item \textbf{LSWMS} (inkl. CLAHE): 64ms
	\item \textbf{Kategorisierung} 2.32ms
	\item \textbf{Segment Joining} 1.05ms
	\item \textbf{Kandidatenevaluation} 9$\mu$s
\end{itemize}

\noindent
Wie zu sehen ist, ist nur der Teil der Kantendetektion für die Gesamtperformance relevant. 

\subsection{Verbesserungsmöglichkeit}
Zwei essentielle Punkte können an der Türerkennung verbessert werden. CLAHE ist eine vergleichsweise rechenintensive Operation. Ohne diese nimmt der LSWMS im Schnitt nur 23ms in Anspruch. Jedoch sind die Suchresultate deutlich schlechter ohne diese Kontrastoptimierung. Hier muss nach einer Alternative gesucht werden.
\paragraph{}
Ein zweiter Schwanchpunkt ist die Ermittlung der Grösse der Tür relativ zur Bildgrösse. Zur Zeit wurd nur die perspektivisch skalierte Höhe der Tür für die Evaluation beigezogen, was zu Fehlerkennungen führt (Abb. \ref{fig:false-door-detection}). Hier muss eine Möglichkeit gefunden werden die Proportionen der Türe zu entzerren, ohne eine rechenintensive Operation wie solvePnP zu verwenden. Ein möglicher Ansatz ist ein Perspective Unwarping zu implementieren.

\begin{figure}	
\center
\includegraphics[width=0.5\textwidth]{images/false-door-detection}
\caption{Falscherkennung aufgrund der perspektivisch skalierten Proportionen}
\label{fig:false-door-detection}
\end{figure}